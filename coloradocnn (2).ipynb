{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:02:16.115151Z","iopub.execute_input":"2025-10-15T06:02:16.115360Z","iopub.status.idle":"2025-10-15T06:02:16.119710Z","shell.execute_reply.started":"2025-10-15T06:02:16.115344Z","shell.execute_reply":"2025-10-15T06:02:16.118842Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install scikeras","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:02:16.121149Z","iopub.execute_input":"2025-10-15T06:02:16.121365Z","iopub.status.idle":"2025-10-15T06:02:23.754833Z","shell.execute_reply.started":"2025-10-15T06:02:16.121350Z","shell.execute_reply":"2025-10-15T06:02:23.754064Z"}},"outputs":[{"name":"stdout","text":"Collecting scikeras\n  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\nRequirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\nCollecting scikit-learn>=1.4.2 (from scikeras)\n  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (14.1.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.1.0)\nRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.14.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.16.0)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (25.0)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.15.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.5.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (2.4.1)\nRequirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.15.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras>=3.2.0->scikeras) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras>=3.2.0->scikeras) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->keras>=3.2.0->scikeras) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->keras>=3.2.0->scikeras) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->keras>=3.2.0->scikeras) (2024.2.0)\nDownloading scikeras-0.13.0-py3-none-any.whl (26 kB)\nDownloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn, scikeras\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikeras-0.13.0 scikit-learn-1.7.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from PIL import Image\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nimport keras_tuner as kt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, Cropping2D, Input, Rescaling\nfrom tensorflow.keras.applications import ResNet50\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom scikeras.wrappers import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import roc_curve, auc\nimport pandas as pd\nimport polars as pl\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:02:23.755747Z","iopub.execute_input":"2025-10-15T06:02:23.755996Z","iopub.status.idle":"2025-10-15T06:02:37.257647Z","shell.execute_reply.started":"2025-10-15T06:02:23.755973Z","shell.execute_reply":"2025-10-15T06:02:37.257031Z"}},"outputs":[{"name":"stderr","text":"2025-10-15 06:02:26.228266: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760508146.398015      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760508146.454126      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"Things that need to be done in this assignment for colorado: \n\n1. describe challenge 5pts\n2. EDA inspect visualise and clean data 15pts\n3. DModel Architecture: dsescribe the model architecture and why I believe this particular one is suitable. Compare multuple architectures and tune hyperparameters (note: use kerastuner for the hyperparameter tuning)\n4. results and analysis Include results with tables and figures for why variopus technoquies or architectures worked or did not work well\n5. interpret results and describe takeaways","metadata":{}},{"cell_type":"code","source":"test_dir = '/kaggle/input/histopathologic-cancer-detection/test/'\ntrain_dir = '/kaggle/input/histopathologic-cancer-detection/train/'\ntrain_labels_file = '/kaggle/input/histopathologic-cancer-detection/train_labels.csv'\ntest_labels_file = '/kaggle/input/histopathologic-cancer-detection/sample_submission.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:02:37.258297Z","iopub.execute_input":"2025-10-15T06:02:37.258709Z","iopub.status.idle":"2025-10-15T06:02:37.262476Z","shell.execute_reply.started":"2025-10-15T06:02:37.258683Z","shell.execute_reply":"2025-10-15T06:02:37.261738Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_image(iid, image_dir=train_dir):\n    path = image_dir + iid + \".tif\"\n\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:02:37.264413Z","iopub.execute_input":"2025-10-15T06:02:37.264659Z","iopub.status.idle":"2025-10-15T06:02:37.302101Z","shell.execute_reply.started":"2025-10-15T06:02:37.264628Z","shell.execute_reply":"2025-10-15T06:02:37.301430Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_labels = pl.read_csv(train_labels_file)\nn_train_subset = int(train_labels.shape[0] * 0.05)\n\nnegative = train_labels.filter(pl.col('label') == 0).sample(n_train_subset)\npositive = train_labels.filter(pl.col('label') == 1).sample(n_train_subset)\nneg_and_pos = pl.concat([negative, positive])\ntrain_labels_subset = neg_and_pos.sample(fraction=1.0, shuffle=True)\n\n# Extract IDs and create paths\ntrain_image_ids = train_labels_subset['id'].to_list()\ntrain_labels_array = train_labels_subset['label'].to_numpy()\n\ntrain_dir = '/kaggle/input/histopathologic-cancer-detection/train/'\ntrain_image_paths = [f\"{train_dir}/{img_id}.tif\" for img_id in train_image_ids]\n\n# Use tf.data for parallel loading\ndef load_and_preprocess(path, label):\n    image = tf.io.read_file(path)\n    image = tf.io.decode_image(image, channels=3, expand_animations=False)\n    image.set_shape([96, 96, 3])\n    image = tf.cast(image, tf.float32) / 255.0\n    # Add GPU-friendly augmentations\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_brightness(image, 0.1)\n    return image, label\n\n# Create dataset\ndataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_labels_array))\ndataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\ndataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:02:37.302828Z","iopub.execute_input":"2025-10-15T06:02:37.303081Z","iopub.status.idle":"2025-10-15T06:02:38.776433Z","shell.execute_reply.started":"2025-10-15T06:02:37.303058Z","shell.execute_reply":"2025-10-15T06:02:38.775749Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1760508158.655956      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Preprocessing we are varying brigthness, orientation intesnity and saturation to avoid overfitting. ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport polars as pl\nimport os\n\n# === Keep Polars Sampling Logic ===\ntrain_labels = pl.read_csv(train_labels_file)\ntest_labels = pl.read_csv(test_labels_file)\n\nn_train_subset = int(train_labels.shape[0] * 0.05)\nnegative = train_labels.filter(pl.col('label') == 0).sample(n_train_subset)\npositive = train_labels.filter(pl.col('label') == 1).sample(n_train_subset)\nneg_and_pos = pl.concat([negative, positive])\ntrain_labels_subset = neg_and_pos.sample(fraction=1.0, shuffle=True)\n\n# Extract IDs and labels\ntrain_image_ids = train_labels_subset['id'].to_list()\ntrain_labels_array = train_labels_subset['label'].to_numpy()\n\n# Base path\ntrain_dir = '/kaggle/input/histopathologic-cancer-detection/train/'\n\n# üîç Auto-detect file extension (.png vs .tif)\nsample_file_png = os.path.join(train_dir, train_image_ids[0] + '.png')\nuse_png = os.path.exists(sample_file_png)\next = 'png' if use_png else 'tif'\n\n# Build full paths\ntrain_image_paths = [os.path.join(train_dir, f\"{img_id}.{ext}\") for img_id in train_image_ids]\n\n# === TensorFlow Preprocessing Pipeline ===\ndef load_and_preprocess_tf(path, label):\n    # Read and decode image\n    image = tf.io.read_file(path)\n    image = tf.io.decode_image(image, channels=3, expand_animations=False)\n    image.set_shape([96, 96, 3])  # Ensure static shape\n    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n\n    # Apply GPU-accelerated augmentations\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_brightness(image, 0.1)\n    image = tf.image.random_contrast(image, 0.9, 1.1)\n    image = tf.image.random_saturation(image, 0.9, 1.1)\n\n    return image, label\n\n# Create dataset\ndataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_labels_array))\n\n# Shuffle for better training dynamics\ndataset = dataset.shuffle(buffer_size=1000, seed=42)\n\n# Map preprocessing with parallelization\ndataset = dataset.map(load_and_preprocess_tf, num_parallel_calls=tf.data.AUTOTUNE)\n\n# Batch and prefetch for performance\ndataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:02:38.777263Z","iopub.execute_input":"2025-10-15T06:02:38.777888Z","iopub.status.idle":"2025-10-15T06:02:40.380541Z","shell.execute_reply.started":"2025-10-15T06:02:38.777862Z","shell.execute_reply":"2025-10-15T06:02:40.379973Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"It is a standard CNN. I did add some batch normalization layers in order to stabilize and improve training. ","metadata":{}},{"cell_type":"code","source":"def build_model(hp):\n    model = Sequential([\n        Input(shape=(96, 96, 3)),\n        Rescaling(1./255),\n        Cropping2D(cropping=32),\n            \n        Conv2D(32, (3,3), activation='relu'),\n        #BatchNormalization(),\n        MaxPooling2D(2,2),\n            \n        Conv2D(hp.Int(\"conv_units\", 64, 128, step=64), (3,3), activation='relu'),\n        BatchNormalization(),\n        MaxPooling2D(2,2),\n            \n        Flatten(),\n        Dense(hp.Int(\"dense_units\", 128, 256, step=128), activation='relu'),\n        Dropout(0.3),\n        BatchNormalization(),\n        Dense(1, activation='sigmoid')\n    ])\n    model.compile(optimizer=Adam(hp.Choice(\"learning_rate\", [1e-4, 1e-3])),\n                  loss='binary_crossentropy', metrics=['accuracy', 'auc'])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:02:40.381239Z","iopub.execute_input":"2025-10-15T06:02:40.381414Z","iopub.status.idle":"2025-10-15T06:02:40.386861Z","shell.execute_reply.started":"2025-10-15T06:02:40.381401Z","shell.execute_reply":"2025-10-15T06:02:40.386150Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# model.compile(optimizer=Adam(hp.Choice(\"learning_rate\", [1e-4, 1e-3])),\n#                   loss='binary_crossentropy', metrics=['accuracy', 'auc'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:02:40.387879Z","iopub.execute_input":"2025-10-15T06:02:40.388382Z","iopub.status.idle":"2025-10-15T06:02:40.403337Z","shell.execute_reply.started":"2025-10-15T06:02:40.388366Z","shell.execute_reply":"2025-10-15T06:02:40.402615Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from tensorflow.keras.utils import load_img, img_to_array\nimport tensorflow as tf\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:02:40.404068Z","iopub.execute_input":"2025-10-15T06:02:40.404373Z","iopub.status.idle":"2025-10-15T06:02:40.420271Z","shell.execute_reply.started":"2025-10-15T06:02:40.404352Z","shell.execute_reply":"2025-10-15T06:02:40.419630Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import keras_tuner\nimport keras","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:02:40.420939Z","iopub.execute_input":"2025-10-15T06:02:40.421194Z","iopub.status.idle":"2025-10-15T06:02:40.432327Z","shell.execute_reply.started":"2025-10-15T06:02:40.421168Z","shell.execute_reply":"2025-10-15T06:02:40.431614Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# X_train, X_val, y_train, y_val = train_test_split(\n#     X, \n#     y, \n#     test_size=0.2, \n#     random_state=42, \n#     stratify=y  # Ensures balanced class distribution\n# )\nimport tensorflow as tf\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\ndesired_height = 96\ndesired_width = 96\n\ndef load_tif_image(path):\n    path = path.numpy().decode(\"utf-8\")\n    img = Image.open(path)\n    arr = np.array(img)\n    return arr\n\ndef load_and_preprocess_tf(path, label):\n    image = tf.py_function(load_tif_image, [path], tf.uint8)\n    image.set_shape([None, None, None])\n    image = tf.image.resize(image, [desired_height, desired_width])\n    image = tf.cast(image, tf.float32) / 255.0\n    return image, label\n\n# Split between training and validation sets\ntrain_paths, val_paths, train_labels, val_labels = train_test_split(\n    train_image_paths,\n    train_labels_array,\n    test_size=0.2,\n    random_state=42,\n    shuffle=True\n)\n\n# Build TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\ntrain_dataset = train_dataset.map(load_and_preprocess_tf, num_parallel_calls=tf.data.AUTOTUNE)\ntrain_dataset = train_dataset.shuffle(1000, seed=42).batch(32).prefetch(tf.data.AUTOTUNE)\n\nval_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\nval_dataset = val_dataset.map(load_and_preprocess_tf, num_parallel_calls=tf.data.AUTOTUNE)\nval_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n\n\n\n\n# tuner = keras_tuner.RandomSearch(\n#     build_model,\n#     objective='val_loss',\n#     max_trials=5,\n#     directory='my_dir',\n#     project_name='my_project',\n#     overwrite=True\n# )\n# #tuner.search(X, y, epochs=5)#, validation_data=(X_val, y_val))\n\n# # Pass the newly created validation set to the search method\n# #tuner.search(X_train, y_train, epochs=5, validation_data=(X_val, y_val))\n# tuner.search(train_dataset, epochs=2, validation_data=(val_dataset))\n# best_hp = tuner.get_best_hyperparameters(1)[0]\n# print(best_hp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:11:24.032114Z","iopub.execute_input":"2025-10-15T06:11:24.032695Z","iopub.status.idle":"2025-10-15T06:11:24.154158Z","shell.execute_reply.started":"2025-10-15T06:11:24.032673Z","shell.execute_reply":"2025-10-15T06:11:24.153556Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"tuner = keras_tuner.Hyperband(\n    hypermodel=build_model,\n    objective=\"val_accuracy\",\n    max_epochs=2,\n    factor=3,\n    hyperband_iterations=1,\n    distribution_strategy=tf.distribute.MirroredStrategy(),\n    directory=\"results_dir\",\n    #project_name=\"mnist\",\n    #overwrite=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:11:26.209988Z","iopub.execute_input":"2025-10-15T06:11:26.210228Z","iopub.status.idle":"2025-10-15T06:11:26.266487Z","shell.execute_reply.started":"2025-10-15T06:11:26.210213Z","shell.execute_reply":"2025-10-15T06:11:26.265959Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"\ntuner.search(train_dataset,validation_data=(val_dataset), callbacks=[keras.callbacks.EarlyStopping(\"val_accuracy\")] )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:11:28.276653Z","iopub.execute_input":"2025-10-15T06:11:28.277158Z","iopub.status.idle":"2025-10-15T06:14:22.373357Z","shell.execute_reply.started":"2025-10-15T06:11:28.277136Z","shell.execute_reply":"2025-10-15T06:14:22.372787Z"}},"outputs":[{"name":"stdout","text":"Trial 2 Complete [00h 01m 15s]\nval_accuracy: 0.7343785762786865\n\nBest val_accuracy So Far: 0.7343785762786865\nTotal elapsed time: 00h 02m 54s\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"best_hp = tuner.get_best_hyperparameters(1)[0]\n\nprint(best_hp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:14:22.374397Z","iopub.execute_input":"2025-10-15T06:14:22.374616Z","iopub.status.idle":"2025-10-15T06:14:22.378702Z","shell.execute_reply.started":"2025-10-15T06:14:22.374577Z","shell.execute_reply":"2025-10-15T06:14:22.377917Z"}},"outputs":[{"name":"stdout","text":"<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x77fc4c1b6550>\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.utils import load_img, img_to_array\n\ntest_dir = '/kaggle/input/histopathologic-cancer-detection/test/'\n\n# List only .tif, .png files\nvalid_extensions = {'.tif', '.tiff', '.png'}\ntest_image_paths = [\n    os.path.join(test_dir, fname) \n    for fname in sorted(os.listdir(test_dir)) \n    if os.path.splitext(fname.lower())[1] in valid_extensions\n]\n\nprint(f\"Found {len(test_image_paths)} image files.\")\n\ndef load_and_preprocess_with_keras(path):\n    try:\n        # Convert Tensor to string\n        path_str = path.numpy().decode('utf-8')\n        # Load image with Keras (uses Pillow, supports all formats)\n        img = load_img(path_str, target_size=(96, 96), color_mode='rgb')\n        image = img_to_array(img)\n        image = tf.cast(image, tf.float32) / 255.0\n        return image\n    except Exception as e:\n        tf.print(f\"Error loading {path_str}: {e}\")\n        # Return blank image to avoid breaking the batch\n        return tf.zeros((96, 96, 3), dtype=tf.float32)\n\n# Use tf.py_function to wrap Python logic\ntest_dataset = tf.data.Dataset.from_tensor_slices(test_image_paths)\ntest_dataset = test_dataset.map(\n    lambda path: tf.py_function(load_and_preprocess_with_keras, [path], tf.float32),\n    num_parallel_calls=tf.data.AUTOTUNE\n)\ntest_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:14:22.379968Z","iopub.execute_input":"2025-10-15T06:14:22.380232Z","iopub.status.idle":"2025-10-15T06:14:23.482323Z","shell.execute_reply.started":"2025-10-15T06:14:22.380209Z","shell.execute_reply":"2025-10-15T06:14:23.481532Z"}},"outputs":[{"name":"stdout","text":"Found 57458 image files.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"best_model = tuner.hypermodel.build(best_hp)\npredictions = best_model.predict(test_dataset)\n\n# Convert probabilities to binary labels (0 or 1)\n# Or keep as probabilities if challenge expects them\npredicted_labels = (predictions > 0.5).astype(int).flatten()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:14:23.483872Z","iopub.execute_input":"2025-10-15T06:14:23.484118Z","iopub.status.idle":"2025-10-15T06:17:03.733312Z","shell.execute_reply.started":"2025-10-15T06:14:23.484101Z","shell.execute_reply":"2025-10-15T06:17:03.732737Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1796/1796\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 88ms/step\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(predicted_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:17:03.734089Z","iopub.execute_input":"2025-10-15T06:17:03.734354Z","iopub.status.idle":"2025-10-15T06:17:03.738637Z","shell.execute_reply.started":"2025-10-15T06:17:03.734330Z","shell.execute_reply":"2025-10-15T06:17:03.738009Z"}},"outputs":[{"name":"stdout","text":"[1 1 1 ... 1 1 1]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import polars as pl\n\n# If you need the correct 'id', uncomment, but ensure path/file exists\nsample_sub = pl.read_csv('/kaggle/input/histopathologic-cancer-detection/sample_submission.csv')\n\n# Create submission DataFrame\nsubmission = pl.DataFrame({\n    'id': sample_sub['id'],  # If you have IDs from sample_sub\n    'label': predicted_labels  # Or y_pred_reshaped.flatten() or your predictions array\n})\n\n# Save to CSV in your current working directory\nsubmission.write_csv('submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:19:16.044719Z","iopub.execute_input":"2025-10-15T06:19:16.045439Z","iopub.status.idle":"2025-10-15T06:19:16.063369Z","shell.execute_reply.started":"2025-10-15T06:19:16.045416Z","shell.execute_reply":"2025-10-15T06:19:16.062650Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"conclusion: I applied a CNN and added batch normilzation to increase accuracy and stabilize training. I applied brigthness, orientation intesnity and saturation to avoid overfitting. ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}